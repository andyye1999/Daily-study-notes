



# 主要功能

对麦克风阵列采集到的信号做声学回声消除和语音增强，定位出主声源的方位角，增强主声源方向的语音信号，抑制噪声和其他方向的干扰，并且减少在语音处理过程中产生的语音失真。

# 系统输入

输入为六路语音信号以及一路背景回声参考信号，其中六路语音信号是由均匀分布的环形六元麦克风阵列采集的，阵列模型如图1所示，语音信号的采样频率为16kHz，室内混响T60为200ms，噪声选用白噪声，信噪比为10dB，回声参考信号要接入外部扬声器以保证被麦克风阵列采集到，阵列直径0.08m

## T60

混响是指室内的声源发声停止后，在室内的声音经过多次反射或散射而延续的现象。它反映了室内声能的衰变，这衰变与室内的吸声，反射和散射等有关。100多年前，美国物理学教授W.C.赛宾首先提出了用声能衰减60dB所需时间

# 性能需求

要求经系统处理后的信号的回声比输入语音信号减弱25dB以上，主声源方向信号的信噪比SNR提高20dB以上，信干比SIR提高15dB以上，系统定位出的主声源方位角与实际主声源的方位角的偏差不超过5°

## 信干燥比

输入功率与（干扰功率、噪声功率之和）的比值

# 子带滤波器

![image](https://cdn.jsdelivr.net/gh/andyye1999/image-hosting@master/20221206/image.jf3zp1ztg4g.webp)

(1) 将输入信号分帧，帧长为160，对分帧后的信号加等长的汉明窗，加窗后的信号通入缓存区，缓存区的长度是原型低通滤波器的阶数。

(2) 原型低通滤波器经过频带搬移得到320个子带滤波器，加窗后的信号通过子带滤波器，再经过类似快速傅里叶变换的加权求和得到320个子带信号，根据实数序列快速傅里叶变换的共轭对称性，只需输出前160个子带信号即可进行后续的算法处理。



```cpp
// 初始化
for (j = 0; j < ORD2; j++)
        prototype_filter[j] = (Float32)(0.54 - 0.46 * cos((2.0 * j + 1) / ORD2)) * (Float32)sin(PI * (2 * j - ORD2 + 1) / (4 * D)) / (Float32)(PI * (2 * j - ORD2 + 1) / 2.0);
    for (k = 0; k < D; k++)
    {
        for (j = 0; j < 2 * D; j++)
        {
            cos_tab0[k][j] = (Float32)cos(2 * PI * k * j / (2 * D));
        }
        for (j = 0; j < 2 * D; j++)
        {
            sin_tab0[k][j] = (Float32)sin(2 * PI * k * j / (2 * D));
        }
    } 
    // 子带滤波  
    for (i = 0; i < 2 * D; i++)
    {
        for (acc2 = 0.0f, j = 0; j < ORD2 / (2 * D); j++)
            acc2 += st->buf_spk[j * 2 * D + i] * prototype_filter[j * 2 * D + i];
        tmp[2 * D - 1 - i] = acc2;
    }
    for (k = 0; k < D; k++)
    {
        for (acc2 = 0.0f, j = 0; j < 2 * D; j++)
            acc2 += tmp[j] * cos_tab0[k][j];
        st->spk_ana_re[k][ORD3 - 1] = acc2;
        for (acc3 = 0.0f, j = 0; j < 2 * D; j++)
            acc3 += tmp[j] * sin_tab0[k][j];
        st->spk_ana_im[k][ORD3 - 1] = acc3;
    }
    // 综合滤波器 还原
    for (i = ORD2 * 2 - 1; i >= 2 * D; i--)
        st->syn[i] = st->syn[i - 2 * D];
    for (i = 0; i < 2 * D; i++)
    {
        for (acc2 = 0.0f, k = 1; k < D; k++)
            acc2 += e_r[0][k] * cos_tab0[k][i] - e_i[0][k] * sin_tab0[k][i];
        st->syn[i] = acc2;
    }
    for (i = 0; i < FRM_LEN; i++)
    {
        for (acc2 = 0.0f, j = 0; j < ORD2 / D; j++)
            acc2 += prototype_filter[j * D + i] * st->syn[j * 2 * D + (j & 1) * D + i];
        temp1[i] = (short)(acc2 * D * 32);
    }
```

![IMG_4291(12-07-14-17-47)](https://cdn.jsdelivr.net/gh/andyye1999/image-hosting@master/20221207/IMG_4291(12-07-14-17-47).51de4tojvf.webp)

![image](https://cdn.jsdelivr.net/gh/andyye1999/image-hosting@master/20230102/image.1rqx0ga4ya8w.webp)



正常是先滤波，再下采样。
每新到一个采样点都进行一次卷积运算，但是后面的抽取过程会丢弃一个点，表明每两次卷积运算就有一次是无用的，因此可以将抽取和滤波调换位置，先进行下采样抽取，再进行卷积滤波。后面的综合过程也是同样的道理，可以将插值和滤波调换位置，让滤波操作在低速率端进行。
所以快速实现是先下采样，跳着乘。这块还是没太明白
看现代数字信号处理书418页
之后做DFT调制
[[信号的抽取与插值与子带滤波器组#DFT调制]]
每个频点=滤出来的点数与cos和sin做求和，类似DFT离散傅里叶变换
这个原型低通滤波器的低通截止频率确实是25，但它和子带分解16000/320=50不一样，50是中心频率，带宽是50，一直平移

# AEC

子带自适应滤波器的阶数设置为20，根据混响时间得出，可以抵抗高达
200ms 的混响。
[[皮尔森系数]]
之前的方法是通过皮尔森系数的4次方，分为几个步长
新的是下面那个代码块
计算皮尔森系数,然后通过如下方法得到可变步长，应该是试出来的
阶数是20阶，相当于缓存了20帧子带滤波后的数据，自适应时对20个更新，但求误差信号时是对20个的和与麦克风信号做差
```cpp
pearson = (Float32)pow(pearson, 2);
	aec_step = (Float32)(10 * pearson + sqrt(10 * pearson)) * (10 * pearson + sqrt(10 * pearson)) / 1000.0f; // 应该是试出来的
```

子带滤波优点：**输入信号的相关性来加快算法收敛速度**

(1) 计算麦克风信号和参考信号的幅度谱和子带能量，进而估计麦克分信号和参考信号之间的皮尔森相关系数。

(2) 将参考信号通过一组自适应滤波器得到模拟回波信号，用预处理后的0号麦克信号减去模拟回声信号得到第一路回波消除后的误差信号。

(3) 根据相关系数的数值选择自适应滤波器的更新步长，然后用误差信号和参考信号更新自适应滤波器的系数。

(4) 将**模拟回波信号信号作为第二至六路的参考信号**，对预处理后的0-5号麦克信号按同样的方法做回声消除以及自适应滤波器的更新。


# NLP

[[webrtc-aec#非线性处理NLP]]

NLMS是线性滤波器并不能消除所有的回声，因为回声的路径不一定是非线性的，因此需要非线性处理来消除这些残余的回声，其基本原理就是信号的频域相干性：近端信号和误差信号的相似度高则不需要进行处理，远端信号和近端信号相似度高则需要进行处理，其中非线性体现在处理是使用指数衰减。

![image](https://cdn.jsdelivr.net/gh/andyye1999/image-hosting@master/20221207/image.1ypia7u6uogw.webp)

![image](https://cdn.jsdelivr.net/gh/andyye1999/image-hosting@master/20221207/image.2jkvx5vp5fc0.webp)

![image](https://cdn.jsdelivr.net/gh/andyye1999/image-hosting@master/20221207/image.3dg7mv9qjcc0.webp)

# 声源定位

博士论文：面向语音通信与交互的麦克风阵列语音增强方法研究

![image](https://cdn.jsdelivr.net/gh/andyye1999/image-hosting@master/20221212/image.2bvpkum1v8bo.webp)


![image](https://cdn.jsdelivr.net/gh/andyye1999/image-hosting@master/20221212/image.1bh510c96xr.webp)

![软著_202212131521_07995-1](https://cdn.jsdelivr.net/gh/andyye1999/image-hosting@master/20221213/软著_202212131521_07995-1.1krmxdbq8nsw.webp)


可控波束响应（Steered-Response Power,SRP）是一种波束成形算法，而通过延迟求和的波束成形器，它可以加强来自任意方向上的信号。在三维定位场景中，SRP算法通过遍历搜索空间中的点，得到该点（潜在的声源点）与麦克风阵列之间的TDoA，再对信号进行延迟求和。遍历空间中的所有点后，SRP算法把输出声音能量最大的点作为估计的声源。
[[TDOA进行声源定位#[TDOA - SRP-PHAT方法](https://www.funcwj.cn/2018/05/29/srp-phat-for-tdoa-estimate/)]]


本程序是求每个方向的所有通道所有频点的能量和，找最大的那个
然后保留7个中排序中间的方位，为主方位

![image](https://cdn.jsdelivr.net/gh/andyye1999/image-hosting@master/20221214/image.25ytxfslqj34.webp)



# GSC
[[GSC]]

# PMWF
[[GSC#[Rank1 Constrained in PMWF](https://www.funcwj.cn/2019/01/10/rank1-const-pmwf/)]]
一行的那个公式，没用求迹的那个
PMWF也叫做**sdw-mwf**

# 合成

综合滤波器组

![image](https://cdn.jsdelivr.net/gh/andyye1999/image-hosting@master/20230102/image.34o54vvzi3k0.webp)


